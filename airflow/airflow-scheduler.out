[2025-02-27T12:31:20.895-0300] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2025-02-27T12:31:21.012-0300] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2025-02-27T12:31:21.013-0300] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2025-02-27T12:31:21.017-0300] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 55248
[2025-02-27T12:31:21.020-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T12:31:22.035-0300] {settings.py:63} INFO - Configured default timezone UTC
[2025-02-27T12:31:22.096-0300] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2025-02-27T12:32:23.168-0300] {manager.py:537} INFO - DAG dbt_pipeline is missing and will be deactivated.
[2025-02-27T12:32:23.179-0300] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-02-27T12:32:23.180-0300] {manager.py:553} INFO - Deleted DAG dbt_pipeline in serialized_dag table
[2025-02-27T12:32:48.763-0300] {dag.py:4180} INFO - Setting next_dagrun for dbt_sequential_pipeline to 2025-02-27 01:00:00+00:00, run_after=2025-02-28 01:00:00+00:00
[2025-02-27T12:32:48.783-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
[2025-02-27T12:32:48.784-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_sequential_pipeline has 0/16 running and queued tasks
[2025-02-27T12:32:48.785-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
[2025-02-27T12:32:48.786-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds scheduled__2025-02-26T01:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:32:48.787-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_seeds', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:32:48.788-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_seeds', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:32:48.789-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_seeds', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:32:49.691-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:32:49.750-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_sequential_pipeline.run_dbt_seeds scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:32:53.276-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_seeds', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:32:53.282-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_sequential_pipeline, task_id=run_dbt_seeds, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:32:49.818870+00:00, run_end_date=2025-02-27 15:32:53.038111+00:00, run_duration=3.219241, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:32:48.786164+00:00, queued_by_job_id=23, pid=55466
[2025-02-27T12:32:53.321-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
[2025-02-27T12:32:53.322-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_sequential_pipeline has 0/16 running and queued tasks
[2025-02-27T12:32:53.323-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
[2025-02-27T12:32:53.325-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model scheduled__2025-02-26T01:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:32:53.326-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_gold_model', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:32:53.327-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_gold_model', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:32:53.328-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_gold_model', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:32:54.193-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:32:54.251-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:32:56.757-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_gold_model', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:32:56.762-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_sequential_pipeline, task_id=run_dbt_gold_model, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:32:54.322395+00:00, run_end_date=2025-02-27 15:32:56.556008+00:00, run_duration=2.233613, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:32:53.324961+00:00, queued_by_job_id=23, pid=55483
[2025-02-27T12:32:56.787-0300] {dagrun.py:854} INFO - Marking run <DagRun dbt_sequential_pipeline @ 2025-02-26 01:00:00+00:00: scheduled__2025-02-26T01:00:00+00:00, state:running, queued_at: 2025-02-27 15:32:48.758522+00:00. externally triggered: False> successful
[2025-02-27T12:32:56.789-0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=dbt_sequential_pipeline, execution_date=2025-02-26 01:00:00+00:00, run_id=scheduled__2025-02-26T01:00:00+00:00, run_start_date=2025-02-27 15:32:48.768721+00:00, run_end_date=2025-02-27 15:32:56.788972+00:00, run_duration=8.020251, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-02-26 01:00:00+00:00, data_interval_end=2025-02-27 01:00:00+00:00, dag_hash=81d60c4d8b25b8f571d921ca2c95e248
[2025-02-27T12:32:56.792-0300] {dag.py:4180} INFO - Setting next_dagrun for dbt_sequential_pipeline to 2025-02-27 01:00:00+00:00, run_after=2025-02-28 01:00:00+00:00
[2025-02-27T12:33:30.559-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:33:29.603310+00:00 [scheduled]>
[2025-02-27T12:33:30.562-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_sequential_pipeline has 0/16 running and queued tasks
[2025-02-27T12:33:30.563-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:33:29.603310+00:00 [scheduled]>
[2025-02-27T12:33:30.565-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:33:29.603310+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:33:30.567-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:33:29.603310+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:33:30.568-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:33:29.603310+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:33:30.570-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:33:29.603310+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:33:31.779-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:33:31.989-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:33:29.603310+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:33:35.086-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:33:29.603310+00:00', try_number=1, map_index=-1)
[2025-02-27T12:33:35.091-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_sequential_pipeline, task_id=run_dbt_seeds, run_id=manual__2025-02-27T15:33:29.603310+00:00, map_index=-1, run_start_date=2025-02-27 15:33:32.123255+00:00, run_end_date=2025-02-27 15:33:34.844171+00:00, run_duration=2.720916, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:33:30.564917+00:00, queued_by_job_id=23, pid=55554
[2025-02-27T12:33:35.121-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:33:29.603310+00:00 [scheduled]>
[2025-02-27T12:33:35.123-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_sequential_pipeline has 0/16 running and queued tasks
[2025-02-27T12:33:35.124-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:33:29.603310+00:00 [scheduled]>
[2025-02-27T12:33:35.125-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:33:29.603310+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:33:35.126-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:33:29.603310+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:33:35.127-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:33:29.603310+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:33:35.129-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:33:29.603310+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:33:36.084-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:33:36.145-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:33:29.603310+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:33:38.788-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:33:29.603310+00:00', try_number=1, map_index=-1)
[2025-02-27T12:33:38.792-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_sequential_pipeline, task_id=run_dbt_gold_model, run_id=manual__2025-02-27T15:33:29.603310+00:00, map_index=-1, run_start_date=2025-02-27 15:33:36.211970+00:00, run_end_date=2025-02-27 15:33:38.576429+00:00, run_duration=2.364459, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:33:35.125063+00:00, queued_by_job_id=23, pid=55566
[2025-02-27T12:34:21.139-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:34:20.003640+00:00 [scheduled]>
[2025-02-27T12:34:21.142-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_sequential_pipeline has 0/16 running and queued tasks
[2025-02-27T12:34:21.143-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:34:20.003640+00:00 [scheduled]>
[2025-02-27T12:34:21.146-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:34:20.003640+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:34:21.147-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:34:20.003640+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:34:21.148-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:34:20.003640+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:34:21.150-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:34:20.003640+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:34:22.308-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:34:22.379-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:34:20.003640+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:34:25.486-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:34:20.003640+00:00', try_number=1, map_index=-1)
[2025-02-27T12:34:25.491-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_sequential_pipeline, task_id=run_dbt_seeds, run_id=manual__2025-02-27T15:34:20.003640+00:00, map_index=-1, run_start_date=2025-02-27 15:34:22.470268+00:00, run_end_date=2025-02-27 15:34:25.303607+00:00, run_duration=2.833339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:34:21.145598+00:00, queued_by_job_id=23, pid=55658
[2025-02-27T12:34:26.784-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:34:20.003640+00:00 [scheduled]>
[2025-02-27T12:34:26.786-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_sequential_pipeline has 0/16 running and queued tasks
[2025-02-27T12:34:26.787-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:34:20.003640+00:00 [scheduled]>
[2025-02-27T12:34:26.789-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:34:20.003640+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:34:26.790-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:34:20.003640+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:34:26.791-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:34:20.003640+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:34:26.792-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:34:20.003640+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:34:27.679-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:34:27.739-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:34:20.003640+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:34:30.411-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:34:20.003640+00:00', try_number=1, map_index=-1)
[2025-02-27T12:34:30.415-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_sequential_pipeline, task_id=run_dbt_gold_model, run_id=manual__2025-02-27T15:34:20.003640+00:00, map_index=-1, run_start_date=2025-02-27 15:34:27.814111+00:00, run_end_date=2025-02-27 15:34:30.210877+00:00, run_duration=2.396766, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:34:26.788575+00:00, queued_by_job_id=23, pid=55680
[2025-02-27T12:35:34.907-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:35:33.759623+00:00 [scheduled]>
[2025-02-27T12:35:34.910-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_sequential_pipeline has 0/16 running and queued tasks
[2025-02-27T12:35:34.911-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:35:33.759623+00:00 [scheduled]>
[2025-02-27T12:35:34.913-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:35:33.759623+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:35:34.914-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:35:33.759623+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:35:34.916-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:35:33.759623+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:35:34.918-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:35:33.759623+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:35:36.007-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:35:36.069-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_sequential_pipeline.run_dbt_seeds manual__2025-02-27T15:35:33.759623+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:35:39.089-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:35:33.759623+00:00', try_number=1, map_index=-1)
[2025-02-27T12:35:39.094-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_sequential_pipeline, task_id=run_dbt_seeds, run_id=manual__2025-02-27T15:35:33.759623+00:00, map_index=-1, run_start_date=2025-02-27 15:35:36.141298+00:00, run_end_date=2025-02-27 15:35:38.899520+00:00, run_duration=2.758222, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:35:34.912773+00:00, queued_by_job_id=23, pid=55825
[2025-02-27T12:35:39.167-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:35:33.759623+00:00 [scheduled]>
[2025-02-27T12:35:39.168-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_sequential_pipeline has 0/16 running and queued tasks
[2025-02-27T12:35:39.169-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:35:33.759623+00:00 [scheduled]>
[2025-02-27T12:35:39.171-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:35:33.759623+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:35:39.172-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:35:33.759623+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:35:39.173-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:35:33.759623+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:35:39.175-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_sequential_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:35:33.759623+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:35:40.119-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:35:40.175-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_sequential_pipeline.run_dbt_gold_model manual__2025-02-27T15:35:33.759623+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:35:43.138-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_sequential_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:35:33.759623+00:00', try_number=1, map_index=-1)
[2025-02-27T12:35:43.142-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_sequential_pipeline, task_id=run_dbt_gold_model, run_id=manual__2025-02-27T15:35:33.759623+00:00, map_index=-1, run_start_date=2025-02-27 15:35:40.235680+00:00, run_end_date=2025-02-27 15:35:42.924132+00:00, run_duration=2.688452, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:35:39.170919+00:00, queued_by_job_id=23, pid=55873
[2025-02-27T12:35:43.165-0300] {dagrun.py:854} INFO - Marking run <DagRun dbt_sequential_pipeline @ 2025-02-27 15:35:33.759623+00:00: manual__2025-02-27T15:35:33.759623+00:00, state:running, queued_at: 2025-02-27 15:35:33.772163+00:00. externally triggered: True> successful
[2025-02-27T12:35:43.167-0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=dbt_sequential_pipeline, execution_date=2025-02-27 15:35:33.759623+00:00, run_id=manual__2025-02-27T15:35:33.759623+00:00, run_start_date=2025-02-27 15:35:34.884979+00:00, run_end_date=2025-02-27 15:35:43.167218+00:00, run_duration=8.282239, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-02-26 01:00:00+00:00, data_interval_end=2025-02-27 01:00:00+00:00, dag_hash=9c3a0113bb1eadb9fa654da341a60107
[2025-02-27T12:36:21.127-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T12:38:26.729-0300] {manager.py:537} INFO - DAG dbt_sequential_pipeline is missing and will be deactivated.
[2025-02-27T12:38:26.735-0300] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2025-02-27T12:38:26.737-0300] {manager.py:553} INFO - Deleted DAG dbt_sequential_pipeline in serialized_dag table
[2025-02-27T12:38:53.052-0300] {dag.py:4180} INFO - Setting next_dagrun for dbt_complete_pipeline to 2025-02-27 01:00:00+00:00, run_after=2025-02-28 01:00:00+00:00
[2025-02-27T12:38:53.077-0300] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_dbt_seeds scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_dbt_seeds manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:38:53.078-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:38:53.079-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 1/16 running and queued tasks
[2025-02-27T12:38:53.081-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_dbt_seeds scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_dbt_seeds manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:38:53.083-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_dbt_seeds scheduled__2025-02-26T01:00:00+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_dbt_seeds manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:38:53.084-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_seeds', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 8 and queue default
[2025-02-27T12:38:53.085-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_seeds', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:38:53.086-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 8 and queue default
[2025-02-27T12:38:53.087-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:38:53.089-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_seeds', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:38:54.129-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:38:54.250-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_dbt_seeds scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:38:57.271-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:38:58.170-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:38:58.225-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_dbt_seeds manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:00.881-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_seeds', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:00.884-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:00.889-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_dbt_seeds, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:38:58.290776+00:00, run_end_date=2025-02-27 15:39:00.694200+00:00, run_duration=2.403424, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-02-27 15:38:53.082403+00:00, queued_by_job_id=23, pid=56328
[2025-02-27T12:39:00.891-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_dbt_seeds, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:38:54.322994+00:00, run_end_date=2025-02-27 15:38:57.120910+00:00, run_duration=2.797916, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=8, operator=BashOperator, queued_dttm=2025-02-27 15:38:53.082403+00:00, queued_by_job_id=23, pid=56309
[2025-02-27T12:39:00.923-0300] {scheduler_job_runner.py:435} INFO - 6 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_stg_payments scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_payments manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_customers scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_orders scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_customers manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_orders manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:39:00.924-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:39:00.925-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 1/16 running and queued tasks
[2025-02-27T12:39:00.925-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 2/16 running and queued tasks
[2025-02-27T12:39:00.926-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 3/16 running and queued tasks
[2025-02-27T12:39:00.927-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 4/16 running and queued tasks
[2025-02-27T12:39:00.928-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 5/16 running and queued tasks
[2025-02-27T12:39:00.929-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_stg_payments scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_payments manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_customers scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_orders scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_customers manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_orders manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:39:00.931-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_stg_payments scheduled__2025-02-26T01:00:00+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_payments manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_customers scheduled__2025-02-26T01:00:00+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_orders scheduled__2025-02-26T01:00:00+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_customers manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_orders manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:39:00.932-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_payments', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-02-27T12:39:00.933-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_payments', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:00.934-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_payments', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-02-27T12:39:00.935-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_payments', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:00.935-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_customers', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-02-27T12:39:00.936-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_customers', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:00.937-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_orders', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-02-27T12:39:00.938-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_orders', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:00.939-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_customers', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-02-27T12:39:00.940-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_customers', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:00.941-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_orders', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-02-27T12:39:00.942-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_orders', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:00.944-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_payments', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:01.857-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:01.913-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_payments scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:04.478-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_payments', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:05.379-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:05.435-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_payments manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:07.982-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_customers', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:08.891-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:08.947-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_customers scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:11.431-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_orders', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:12.303-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:12.359-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_orders scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:14.821-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_customers', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:15.755-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:15.811-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_customers manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:18.330-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_orders', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:19.194-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:19.250-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_orders manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:21.934-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_payments', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:21.936-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_payments', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:21.938-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_customers', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:21.939-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_orders', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:21.940-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_customers', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:21.941-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_orders', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:21.946-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_customers, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:39:09.016212+00:00, run_end_date=2025-02-27 15:39:11.281518+00:00, run_duration=2.265306, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-02-27 15:39:00.930596+00:00, queued_by_job_id=23, pid=56368
[2025-02-27T12:39:21.947-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_orders, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:39:12.424951+00:00, run_end_date=2025-02-27 15:39:14.629424+00:00, run_duration=2.204473, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-02-27 15:39:00.930596+00:00, queued_by_job_id=23, pid=56378
[2025-02-27T12:39:21.949-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_payments, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:39:01.980423+00:00, run_end_date=2025-02-27 15:39:04.309498+00:00, run_duration=2.329075, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=26, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-02-27 15:39:00.930596+00:00, queued_by_job_id=23, pid=56340
[2025-02-27T12:39:21.950-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_customers, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:39:15.876769+00:00, run_end_date=2025-02-27 15:39:18.184317+00:00, run_duration=2.307548, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-02-27 15:39:00.930596+00:00, queued_by_job_id=23, pid=56391
[2025-02-27T12:39:21.951-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_orders, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:39:19.316124+00:00, run_end_date=2025-02-27 15:39:21.775823+00:00, run_duration=2.459699, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-02-27 15:39:00.930596+00:00, queued_by_job_id=23, pid=56401
[2025-02-27T12:39:21.953-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_payments, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:39:05.501297+00:00, run_end_date=2025-02-27 15:39:07.787994+00:00, run_duration=2.286697, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-02-27 15:39:00.930596+00:00, queued_by_job_id=23, pid=56355
[2025-02-27T12:39:23.086-0300] {scheduler_job_runner.py:435} INFO - 6 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_customers scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_orders scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_customers manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_orders manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:39:23.088-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:39:23.088-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 1/16 running and queued tasks
[2025-02-27T12:39:23.089-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 2/16 running and queued tasks
[2025-02-27T12:39:23.090-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 3/16 running and queued tasks
[2025-02-27T12:39:23.091-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 4/16 running and queued tasks
[2025-02-27T12:39:23.092-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 5/16 running and queued tasks
[2025-02-27T12:39:23.093-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_customers scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_orders scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_customers manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_orders manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:39:23.094-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_customers scheduled__2025-02-26T01:00:00+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_orders scheduled__2025-02-26T01:00:00+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_customers manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_orders manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:39:23.095-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_customers', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:39:23.096-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_customers', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:23.097-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_orders', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:39:23.098-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_orders', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:23.099-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:39:23.100-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:23.101-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_customers', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:39:23.102-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_customers', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:23.103-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_orders', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:39:23.104-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_orders', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:23.105-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:39:23.106-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:23.107-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_customers', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:23.959-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:24.014-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_customers scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:26.551-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_orders', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:27.413-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:27.469-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_orders scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:29.998-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:30.794-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:30.851-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_products scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:33.581-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_customers', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:34.430-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:34.486-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_customers manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:37.072-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_orders', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:37.999-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:38.107-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_orders manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:40.712-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:39:41.627-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:39:41.683-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:39:44.190-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_customers', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:44.193-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_orders', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:44.194-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:44.195-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_customers', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:44.196-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_orders', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:44.197-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:39:44.201-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_customers, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:39:24.082617+00:00, run_end_date=2025-02-27 15:39:26.356501+00:00, run_duration=2.273884, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:39:23.094045+00:00, queued_by_job_id=23, pid=56417
[2025-02-27T12:39:44.203-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_orders, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:39:27.543622+00:00, run_end_date=2025-02-27 15:39:29.842878+00:00, run_duration=2.299256, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:39:23.094045+00:00, queued_by_job_id=23, pid=56427
[2025-02-27T12:39:44.204-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_products, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:39:30.918587+00:00, run_end_date=2025-02-27 15:39:33.285623+00:00, run_duration=2.367036, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:39:23.094045+00:00, queued_by_job_id=23, pid=56437
[2025-02-27T12:39:44.205-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_customers, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:39:34.553382+00:00, run_end_date=2025-02-27 15:39:36.890510+00:00, run_duration=2.337128, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:39:23.094045+00:00, queued_by_job_id=23, pid=56449
[2025-02-27T12:39:44.207-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_orders, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:39:38.173279+00:00, run_end_date=2025-02-27 15:39:40.529689+00:00, run_duration=2.35641, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:39:23.094045+00:00, queued_by_job_id=23, pid=56489
[2025-02-27T12:39:44.208-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_products, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:39:41.750280+00:00, run_end_date=2025-02-27 15:39:43.940582+00:00, run_duration=2.190302, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:39:23.094045+00:00, queued_by_job_id=23, pid=56503
[2025-02-27T12:41:02.786-0300] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_stg_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:41:02.788-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:41:02.790-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 1/16 running and queued tasks
[2025-02-27T12:41:02.791-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_stg_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:41:02.793-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_stg_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:41:02.794-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_products', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:41:02.795-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_products', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:41:02.796-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_products', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:41:02.797-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_products', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:41:02.799-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_products', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:41:03.723-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:41:03.783-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_products scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:41:06.980-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_products', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:41:07.867-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:41:07.923-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_products manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:41:10.562-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_products', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:41:10.565-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_products', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:41:10.568-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_products, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:41:07.990275+00:00, run_end_date=2025-02-27 15:41:10.366606+00:00, run_duration=2.376331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:41:02.792713+00:00, queued_by_job_id=23, pid=56747
[2025-02-27T12:41:10.571-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_products, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:41:03.852454+00:00, run_end_date=2025-02-27 15:41:06.779978+00:00, run_duration=2.927524, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:41:02.792713+00:00, queued_by_job_id=23, pid=56726
[2025-02-27T12:41:21.174-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T12:42:03.216-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:42:03.219-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:42:03.221-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:42:03.222-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:42:03.224-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:42:03.225-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:03.227-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:04.213-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:04.273-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:06.948-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=2, map_index=-1)
[2025-02-27T12:42:06.952-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_products, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=2025-02-27 15:42:04.329745+00:00, run_end_date=2025-02-27 15:42:06.802375+00:00, run_duration=2.47263, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=2, job_id=40, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:42:03.222336+00:00, queued_by_job_id=23, pid=56894
[2025-02-27T12:42:08.108-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:42:08.109-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:42:08.110-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>
[2025-02-27T12:42:08.113-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:38:52.327011+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:42:08.114-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:42:08.115-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:08.116-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:38:52.327011+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:09.090-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:09.146-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:38:52.327011+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:09.335-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:38:52.327011+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:09.339-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_dbt_gold_model, run_id=manual__2025-02-27T15:38:52.327011+00:00, map_index=-1, run_start_date=None, run_end_date=2025-02-27 15:42:02.648691+00:00, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:42:08.111471+00:00, queued_by_job_id=23, pid=None
[2025-02-27T12:42:09.341-0300] {scheduler_job_runner.py:922} ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:38:52.327011+00:00 [queued]> finished with state success, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2025-02-27T12:42:09.345-0300] {taskinstance.py:3315} ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:38:52.327011+00:00 [queued]> finished with state success, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2025-02-27T12:42:09.352-0300] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=dbt_complete_pipeline, task_id=run_dbt_gold_model, run_id=manual__2025-02-27T15:38:52.327011+00:00, execution_date=20250227T153852, start_date=, end_date=20250227T154209
[2025-02-27T12:42:10.460-0300] {dagrun.py:823} ERROR - Marking run <DagRun dbt_complete_pipeline @ 2025-02-27 15:38:52.327011+00:00: manual__2025-02-27T15:38:52.327011+00:00, state:running, queued_at: 2025-02-27 15:38:52.343464+00:00. externally triggered: True> failed
[2025-02-27T12:42:10.463-0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=dbt_complete_pipeline, execution_date=2025-02-27 15:38:52.327011+00:00, run_id=manual__2025-02-27T15:38:52.327011+00:00, run_start_date=2025-02-27 15:38:53.062373+00:00, run_end_date=2025-02-27 15:42:10.463586+00:00, run_duration=197.401213, state=failed, external_trigger=True, run_type=manual, data_interval_start=2025-02-26 01:00:00+00:00, data_interval_end=2025-02-27 01:00:00+00:00, dag_hash=87f87c7f206534e6642561726bb5ba2a
[2025-02-27T12:42:26.296-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_dbt_seeds manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
[2025-02-27T12:42:26.299-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:42:26.300-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_dbt_seeds manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
[2025-02-27T12:42:26.302-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_dbt_seeds manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:42:26.303-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 9 and queue default
[2025-02-27T12:42:26.305-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:26.306-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_seeds', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:27.363-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:27.424-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_dbt_seeds manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:30.295-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_seeds', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:30.300-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_dbt_seeds, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:27.489520+00:00, run_end_date=2025-02-27 15:42:30.055657+00:00, run_duration=2.566137, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=9, operator=BashOperator, queued_dttm=2025-02-27 15:42:26.301887+00:00, queued_by_job_id=23, pid=56950
[2025-02-27T12:42:30.334-0300] {scheduler_job_runner.py:435} INFO - 4 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_stg_payments manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_customers manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_orders manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_products manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
[2025-02-27T12:42:30.335-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:42:30.336-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 1/16 running and queued tasks
[2025-02-27T12:42:30.337-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 2/16 running and queued tasks
[2025-02-27T12:42:30.338-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 3/16 running and queued tasks
[2025-02-27T12:42:30.339-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_stg_payments manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_customers manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_orders manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_stg_products manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
[2025-02-27T12:42:30.341-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_stg_payments manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_customers manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_orders manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_stg_products manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:42:30.342-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_payments', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2025-02-27T12:42:30.343-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_payments', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:30.344-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_customers', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-02-27T12:42:30.345-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_customers', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:30.346-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_orders', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
[2025-02-27T12:42:30.347-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_orders', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:30.348-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_products', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:42:30.349-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_products', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:30.351-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_payments', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:31.191-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:31.247-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_payments manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:33.935-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_customers', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:34.836-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:34.892-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_customers manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:37.484-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_orders', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:38.342-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:38.398-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_orders manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:40.901-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_stg_products', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:41.808-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:41.866-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_stg_products manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:44.439-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_payments', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:44.441-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_customers', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:44.442-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_orders', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:44.443-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_stg_products', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:44.447-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_customers, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:34.957472+00:00, run_end_date=2025-02-27 15:42:37.295371+00:00, run_duration=2.337899, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-02-27 15:42:30.340683+00:00, queued_by_job_id=23, pid=56978
[2025-02-27T12:42:44.449-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_orders, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:38.462649+00:00, run_end_date=2025-02-27 15:42:40.727239+00:00, run_duration=2.26459, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2025-02-27 15:42:30.340683+00:00, queued_by_job_id=23, pid=56989
[2025-02-27T12:42:44.450-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_payments, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:31.310650+00:00, run_end_date=2025-02-27 15:42:33.701727+00:00, run_duration=2.391077, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2025-02-27 15:42:30.340683+00:00, queued_by_job_id=23, pid=56963
[2025-02-27T12:42:44.451-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_stg_products, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:41.930547+00:00, run_end_date=2025-02-27 15:42:44.254826+00:00, run_duration=2.324279, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:42:30.340683+00:00, queued_by_job_id=23, pid=57001
[2025-02-27T12:42:45.649-0300] {scheduler_job_runner.py:435} INFO - 3 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_customers manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_orders manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
[2025-02-27T12:42:45.650-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:42:45.651-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 1/16 running and queued tasks
[2025-02-27T12:42:45.652-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 2/16 running and queued tasks
[2025-02-27T12:42:45.653-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_customers manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_orders manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
	<TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
[2025-02-27T12:42:45.654-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_customers manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_orders manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>, <TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:42:45.655-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_customers', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:42:45.656-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_customers', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:45.656-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_orders', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:42:45.657-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_orders', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:45.658-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:42:45.659-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:45.660-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_customers', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:46.519-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:46.574-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_customers manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:49.051-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_orders', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:50.088-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:50.145-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_orders manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:52.848-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:53.934-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:53.992-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_products manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:42:56.584-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_customers', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:56.587-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_orders', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:56.588-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:42:56.592-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_customers, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:46.639247+00:00, run_end_date=2025-02-27 15:42:48.871261+00:00, run_duration=2.232014, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=47, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:42:45.654004+00:00, queued_by_job_id=23, pid=57015
[2025-02-27T12:42:56.594-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_orders, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:50.212486+00:00, run_end_date=2025-02-27 15:42:52.641899+00:00, run_duration=2.429413, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:42:45.654004+00:00, queued_by_job_id=23, pid=57027
[2025-02-27T12:42:56.595-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_products, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:54.063596+00:00, run_end_date=2025-02-27 15:42:56.397189+00:00, run_duration=2.333593, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=49, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:42:45.654004+00:00, queued_by_job_id=23, pid=57044
[2025-02-27T12:42:56.671-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
[2025-02-27T12:42:56.673-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:42:56.674-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>
[2025-02-27T12:42:56.676-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:42:25.303422+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:42:56.677-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:42:56.678-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:56.680-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_gold_model', 'manual__2025-02-27T15:42:25.303422+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:42:57.709-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:42:57.764-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_dbt_gold_model manual__2025-02-27T15:42:25.303422+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:43:00.343-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_gold_model', run_id='manual__2025-02-27T15:42:25.303422+00:00', try_number=1, map_index=-1)
[2025-02-27T12:43:00.348-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_dbt_gold_model, run_id=manual__2025-02-27T15:42:25.303422+00:00, map_index=-1, run_start_date=2025-02-27 15:42:57.831136+00:00, run_end_date=2025-02-27 15:43:00.162042+00:00, run_duration=2.330906, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=50, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:42:56.675880+00:00, queued_by_job_id=23, pid=57063
[2025-02-27T12:43:00.371-0300] {dagrun.py:854} INFO - Marking run <DagRun dbt_complete_pipeline @ 2025-02-27 15:42:25.303422+00:00: manual__2025-02-27T15:42:25.303422+00:00, state:running, queued_at: 2025-02-27 15:42:25.311134+00:00. externally triggered: True> successful
[2025-02-27T12:43:00.373-0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=dbt_complete_pipeline, execution_date=2025-02-27 15:42:25.303422+00:00, run_id=manual__2025-02-27T15:42:25.303422+00:00, run_start_date=2025-02-27 15:42:26.275578+00:00, run_end_date=2025-02-27 15:43:00.373178+00:00, run_duration=34.0976, state=success, external_trigger=True, run_type=manual, data_interval_start=2025-02-26 01:00:00+00:00, data_interval_end=2025-02-27 01:00:00+00:00, dag_hash=87f87c7f206534e6642561726bb5ba2a
[2025-02-27T12:44:33.415-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
[2025-02-27T12:44:33.418-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:44:33.419-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
[2025-02-27T12:44:33.421-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_products scheduled__2025-02-26T01:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:44:33.423-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2025-02-27T12:44:33.424-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:44:33.426-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_products', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:44:34.611-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:44:34.672-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_products scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:44:37.563-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_products', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=2, map_index=-1)
[2025-02-27T12:44:37.570-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_products, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:44:34.739962+00:00, run_end_date=2025-02-27 15:44:37.372534+00:00, run_duration=2.632572, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=51, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2025-02-27 15:44:33.421163+00:00, queued_by_job_id=23, pid=57310
[2025-02-27T12:44:37.600-0300] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
[2025-02-27T12:44:37.602-0300] {scheduler_job_runner.py:507} INFO - DAG dbt_complete_pipeline has 0/16 running and queued tasks
[2025-02-27T12:44:37.603-0300] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model scheduled__2025-02-26T01:00:00+00:00 [scheduled]>
[2025-02-27T12:44:37.604-0300] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: dbt_complete_pipeline.run_dbt_gold_model scheduled__2025-02-26T01:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2025-02-27T12:44:37.605-0300] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_gold_model', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2025-02-27T12:44:37.606-0300] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_gold_model', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:44:37.608-0300] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'dbt_complete_pipeline', 'run_dbt_gold_model', 'scheduled__2025-02-26T01:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/dbt_gold_model_dag.py']
[2025-02-27T12:44:38.515-0300] {dagbag.py:588} INFO - Filling up the DagBag from /Users/bruno/dbt_testing/airflow/dags/dbt_gold_model_dag.py
[2025-02-27T12:44:38.572-0300] {task_command.py:467} INFO - Running <TaskInstance: dbt_complete_pipeline.run_dbt_gold_model scheduled__2025-02-26T01:00:00+00:00 [queued]> on host 192.168.1.95
[2025-02-27T12:44:41.197-0300] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dbt_complete_pipeline', task_id='run_dbt_gold_model', run_id='scheduled__2025-02-26T01:00:00+00:00', try_number=1, map_index=-1)
[2025-02-27T12:44:41.204-0300] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=dbt_complete_pipeline, task_id=run_dbt_gold_model, run_id=scheduled__2025-02-26T01:00:00+00:00, map_index=-1, run_start_date=2025-02-27 15:44:38.634350+00:00, run_end_date=2025-02-27 15:44:41.005575+00:00, run_duration=2.371225, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=52, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2025-02-27 15:44:37.604272+00:00, queued_by_job_id=23, pid=57325
[2025-02-27T12:44:41.225-0300] {dagrun.py:854} INFO - Marking run <DagRun dbt_complete_pipeline @ 2025-02-26 01:00:00+00:00: scheduled__2025-02-26T01:00:00+00:00, state:running, queued_at: 2025-02-27 15:38:53.046433+00:00. externally triggered: False> successful
[2025-02-27T12:44:41.226-0300] {dagrun.py:905} INFO - DagRun Finished: dag_id=dbt_complete_pipeline, execution_date=2025-02-26 01:00:00+00:00, run_id=scheduled__2025-02-26T01:00:00+00:00, run_start_date=2025-02-27 15:38:53.062041+00:00, run_end_date=2025-02-27 15:44:41.226733+00:00, run_duration=348.164692, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-02-26 01:00:00+00:00, data_interval_end=2025-02-27 01:00:00+00:00, dag_hash=22a846a66065d2fe9020ddb3f88d5002
[2025-02-27T12:44:41.229-0300] {dag.py:4180} INFO - Setting next_dagrun for dbt_complete_pipeline to 2025-02-27 01:00:00+00:00, run_after=2025-02-28 01:00:00+00:00
[2025-02-27T12:46:21.233-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T12:51:21.276-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T12:56:21.320-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:01:21.297-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:06:21.345-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:11:21.393-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:16:21.464-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:21:21.512-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:26:21.545-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:31:21.531-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:36:21.576-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:41:21.620-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2025-02-27T13:46:21.619-0300] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
